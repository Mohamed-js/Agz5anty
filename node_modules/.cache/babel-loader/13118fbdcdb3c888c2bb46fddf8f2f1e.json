{"ast":null,"code":"import _regeneratorRuntime from \"@babel/runtime/regenerator\";\n\nfunction asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }\n\nfunction _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"next\", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"throw\", err); } _next(undefined); }); }; }\n\nimport { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport var createAnalyserNodeRendererFactory = function createAnalyserNodeRendererFactory(createNativeAnalyserNode, getNativeAudioNode, renderInputsOfAudioNode) {\n  return function () {\n    var renderedNativeAnalyserNodes = new WeakMap();\n\n    var createAnalyserNode = /*#__PURE__*/function () {\n      var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(proxy, nativeOfflineAudioContext, trace) {\n        var nativeAnalyserNode, nativeAnalyserNodeIsOwnedByContext, options;\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                nativeAnalyserNode = getNativeAudioNode(proxy); // If the initially used nativeAnalyserNode was not constructed on the same OfflineAudioContext it needs to be created again.\n\n                nativeAnalyserNodeIsOwnedByContext = isOwnedByContext(nativeAnalyserNode, nativeOfflineAudioContext);\n\n                if (!nativeAnalyserNodeIsOwnedByContext) {\n                  options = {\n                    channelCount: nativeAnalyserNode.channelCount,\n                    channelCountMode: nativeAnalyserNode.channelCountMode,\n                    channelInterpretation: nativeAnalyserNode.channelInterpretation,\n                    fftSize: nativeAnalyserNode.fftSize,\n                    maxDecibels: nativeAnalyserNode.maxDecibels,\n                    minDecibels: nativeAnalyserNode.minDecibels,\n                    smoothingTimeConstant: nativeAnalyserNode.smoothingTimeConstant\n                  };\n                  nativeAnalyserNode = createNativeAnalyserNode(nativeOfflineAudioContext, options);\n                }\n\n                renderedNativeAnalyserNodes.set(nativeOfflineAudioContext, nativeAnalyserNode);\n                _context.next = 6;\n                return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAnalyserNode, trace);\n\n              case 6:\n                return _context.abrupt(\"return\", nativeAnalyserNode);\n\n              case 7:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee);\n      }));\n\n      return function createAnalyserNode(_x, _x2, _x3) {\n        return _ref.apply(this, arguments);\n      };\n    }();\n\n    return {\n      render: function render(proxy, nativeOfflineAudioContext, trace) {\n        var renderedNativeAnalyserNode = renderedNativeAnalyserNodes.get(nativeOfflineAudioContext);\n\n        if (renderedNativeAnalyserNode !== undefined) {\n          return Promise.resolve(renderedNativeAnalyserNode);\n        }\n\n        return createAnalyserNode(proxy, nativeOfflineAudioContext, trace);\n      }\n    };\n  };\n};","map":null,"metadata":{},"sourceType":"module"}