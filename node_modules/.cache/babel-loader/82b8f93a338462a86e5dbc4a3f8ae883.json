{"ast":null,"code":"import _regeneratorRuntime from \"@babel/runtime/regenerator\";\n\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nfunction asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }\n\nfunction _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"next\", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"throw\", err); } _next(undefined); }); }; }\n\nimport { isNativeAudioNodeFaker } from '../guards/native-audio-node-faker';\nimport { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport var createPannerNodeRendererFactory = function createPannerNodeRendererFactory(connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeGainNode, createNativePannerNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext) {\n  return function () {\n    var renderedNativeAudioNodes = new WeakMap();\n    var renderedBufferPromise = null;\n\n    var createAudioNode = /*#__PURE__*/function () {\n      var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(proxy, nativeOfflineAudioContext, trace) {\n        var nativeGainNode, nativePannerNode, commonAudioNodeOptions, commonNativePannerNodeOptions, nativePannerNodeIsOwnedByContext, options, _ret;\n\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                nativeGainNode = null;\n                nativePannerNode = getNativeAudioNode(proxy);\n                commonAudioNodeOptions = {\n                  channelCount: nativePannerNode.channelCount,\n                  channelCountMode: nativePannerNode.channelCountMode,\n                  channelInterpretation: nativePannerNode.channelInterpretation\n                };\n                commonNativePannerNodeOptions = _objectSpread(_objectSpread({}, commonAudioNodeOptions), {}, {\n                  coneInnerAngle: nativePannerNode.coneInnerAngle,\n                  coneOuterAngle: nativePannerNode.coneOuterAngle,\n                  coneOuterGain: nativePannerNode.coneOuterGain,\n                  distanceModel: nativePannerNode.distanceModel,\n                  maxDistance: nativePannerNode.maxDistance,\n                  panningModel: nativePannerNode.panningModel,\n                  refDistance: nativePannerNode.refDistance,\n                  rolloffFactor: nativePannerNode.rolloffFactor\n                }); // If the initially used nativePannerNode was not constructed on the same OfflineAudioContext it needs to be created again.\n\n                nativePannerNodeIsOwnedByContext = isOwnedByContext(nativePannerNode, nativeOfflineAudioContext); // Bug #124: Safari does not support modifying the orientation and the position with AudioParams.\n\n                if ('bufferSize' in nativePannerNode) {\n                  nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, _objectSpread(_objectSpread({}, commonAudioNodeOptions), {}, {\n                    gain: 1\n                  }));\n                } else if (!nativePannerNodeIsOwnedByContext) {\n                  options = _objectSpread(_objectSpread({}, commonNativePannerNodeOptions), {}, {\n                    orientationX: nativePannerNode.orientationX.value,\n                    orientationY: nativePannerNode.orientationY.value,\n                    orientationZ: nativePannerNode.orientationZ.value,\n                    positionX: nativePannerNode.positionX.value,\n                    positionY: nativePannerNode.positionY.value,\n                    positionZ: nativePannerNode.positionZ.value\n                  });\n                  nativePannerNode = createNativePannerNode(nativeOfflineAudioContext, options);\n                }\n\n                renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeGainNode === null ? nativePannerNode : nativeGainNode);\n\n                if (!(nativeGainNode !== null)) {\n                  _context4.next = 12;\n                  break;\n                }\n\n                return _context4.delegateYield( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3() {\n                  var partialOfflineAudioContext, nativeChannelMergerNode, renderedBuffer, inputGainNode, channelDatas, i, lastOrientation, lastPosition, gateGainNode, partialPannerNode, _i, orientation, positon, currentTime;\n\n                  return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n                    while (1) {\n                      switch (_context3.prev = _context3.next) {\n                        case 0:\n                          if (!(renderedBufferPromise === null)) {\n                            _context3.next = 7;\n                            break;\n                          }\n\n                          if (!(nativeOfflineAudioContextConstructor === null)) {\n                            _context3.next = 3;\n                            break;\n                          }\n\n                          throw new Error('Missing the native OfflineAudioContext constructor.');\n\n                        case 3:\n                          partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(6, // Bug #17: Safari does not yet expose the length.\n                          proxy.context.length, nativeOfflineAudioContext.sampleRate);\n                          nativeChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {\n                            channelCount: 1,\n                            channelCountMode: 'explicit',\n                            channelInterpretation: 'speakers',\n                            numberOfInputs: 6\n                          });\n                          nativeChannelMergerNode.connect(partialOfflineAudioContext.destination);\n                          renderedBufferPromise = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {\n                            var nativeConstantSourceNodes, i;\n                            return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n                              while (1) {\n                                switch (_context2.prev = _context2.next) {\n                                  case 0:\n                                    _context2.next = 2;\n                                    return Promise.all([proxy.orientationX, proxy.orientationY, proxy.orientationZ, proxy.positionX, proxy.positionY, proxy.positionZ].map( /*#__PURE__*/function () {\n                                      var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(audioParam, index) {\n                                        var nativeConstantSourceNode;\n                                        return _regeneratorRuntime.wrap(function _callee$(_context) {\n                                          while (1) {\n                                            switch (_context.prev = _context.next) {\n                                              case 0:\n                                                nativeConstantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {\n                                                  channelCount: 1,\n                                                  channelCountMode: 'explicit',\n                                                  channelInterpretation: 'discrete',\n                                                  offset: index === 0 ? 1 : 0\n                                                });\n                                                _context.next = 3;\n                                                return renderAutomation(partialOfflineAudioContext, audioParam, nativeConstantSourceNode.offset, trace);\n\n                                              case 3:\n                                                return _context.abrupt(\"return\", nativeConstantSourceNode);\n\n                                              case 4:\n                                              case \"end\":\n                                                return _context.stop();\n                                            }\n                                          }\n                                        }, _callee);\n                                      }));\n\n                                      return function (_x4, _x5) {\n                                        return _ref3.apply(this, arguments);\n                                      };\n                                    }()));\n\n                                  case 2:\n                                    nativeConstantSourceNodes = _context2.sent;\n\n                                    for (i = 0; i < 6; i += 1) {\n                                      nativeConstantSourceNodes[i].connect(nativeChannelMergerNode, 0, i);\n                                      nativeConstantSourceNodes[i].start(0);\n                                    }\n\n                                    return _context2.abrupt(\"return\", renderNativeOfflineAudioContext(partialOfflineAudioContext));\n\n                                  case 5:\n                                  case \"end\":\n                                    return _context2.stop();\n                                }\n                              }\n                            }, _callee2);\n                          }))();\n\n                        case 7:\n                          _context3.next = 9;\n                          return renderedBufferPromise;\n\n                        case 9:\n                          renderedBuffer = _context3.sent;\n                          inputGainNode = createNativeGainNode(nativeOfflineAudioContext, _objectSpread(_objectSpread({}, commonAudioNodeOptions), {}, {\n                            gain: 1\n                          }));\n                          _context3.next = 13;\n                          return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, inputGainNode, trace);\n\n                        case 13:\n                          channelDatas = [];\n\n                          for (i = 0; i < renderedBuffer.numberOfChannels; i += 1) {\n                            channelDatas.push(renderedBuffer.getChannelData(i));\n                          }\n\n                          lastOrientation = [channelDatas[0][0], channelDatas[1][0], channelDatas[2][0]];\n                          lastPosition = [channelDatas[3][0], channelDatas[4][0], channelDatas[5][0]];\n                          gateGainNode = createNativeGainNode(nativeOfflineAudioContext, _objectSpread(_objectSpread({}, commonAudioNodeOptions), {}, {\n                            gain: 1\n                          }));\n                          partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, _objectSpread(_objectSpread({}, commonNativePannerNodeOptions), {}, {\n                            orientationX: lastOrientation[0],\n                            orientationY: lastOrientation[1],\n                            orientationZ: lastOrientation[2],\n                            positionX: lastPosition[0],\n                            positionY: lastPosition[1],\n                            positionZ: lastPosition[2]\n                          }));\n                          inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);\n                          partialPannerNode.connect(nativeGainNode);\n\n                          for (_i = 128; _i < renderedBuffer.length; _i += 128) {\n                            orientation = [channelDatas[0][_i], channelDatas[1][_i], channelDatas[2][_i]];\n                            positon = [channelDatas[3][_i], channelDatas[4][_i], channelDatas[5][_i]];\n\n                            if (orientation.some(function (value, index) {\n                              return value !== lastOrientation[index];\n                            }) || positon.some(function (value, index) {\n                              return value !== lastPosition[index];\n                            })) {\n                              lastOrientation = orientation;\n                              lastPosition = positon;\n                              currentTime = _i / nativeOfflineAudioContext.sampleRate;\n                              gateGainNode.gain.setValueAtTime(0, currentTime);\n                              gateGainNode = createNativeGainNode(nativeOfflineAudioContext, _objectSpread(_objectSpread({}, commonAudioNodeOptions), {}, {\n                                gain: 0\n                              }));\n                              partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, _objectSpread(_objectSpread({}, commonNativePannerNodeOptions), {}, {\n                                orientationX: lastOrientation[0],\n                                orientationY: lastOrientation[1],\n                                orientationZ: lastOrientation[2],\n                                positionX: lastPosition[0],\n                                positionY: lastPosition[1],\n                                positionZ: lastPosition[2]\n                              }));\n                              gateGainNode.gain.setValueAtTime(1, currentTime);\n                              inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);\n                              partialPannerNode.connect(nativeGainNode);\n                            }\n                          }\n\n                          return _context3.abrupt(\"return\", {\n                            v: nativeGainNode\n                          });\n\n                        case 23:\n                        case \"end\":\n                          return _context3.stop();\n                      }\n                    }\n                  }, _callee3);\n                })(), \"t0\", 9);\n\n              case 9:\n                _ret = _context4.t0;\n\n                if (!(_typeof(_ret) === \"object\")) {\n                  _context4.next = 12;\n                  break;\n                }\n\n                return _context4.abrupt(\"return\", _ret.v);\n\n              case 12:\n                if (nativePannerNodeIsOwnedByContext) {\n                  _context4.next = 27;\n                  break;\n                }\n\n                _context4.next = 15;\n                return renderAutomation(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX, trace);\n\n              case 15:\n                _context4.next = 17;\n                return renderAutomation(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY, trace);\n\n              case 17:\n                _context4.next = 19;\n                return renderAutomation(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ, trace);\n\n              case 19:\n                _context4.next = 21;\n                return renderAutomation(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX, trace);\n\n              case 21:\n                _context4.next = 23;\n                return renderAutomation(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY, trace);\n\n              case 23:\n                _context4.next = 25;\n                return renderAutomation(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ, trace);\n\n              case 25:\n                _context4.next = 39;\n                break;\n\n              case 27:\n                _context4.next = 29;\n                return connectAudioParam(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX, trace);\n\n              case 29:\n                _context4.next = 31;\n                return connectAudioParam(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY, trace);\n\n              case 31:\n                _context4.next = 33;\n                return connectAudioParam(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ, trace);\n\n              case 33:\n                _context4.next = 35;\n                return connectAudioParam(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX, trace);\n\n              case 35:\n                _context4.next = 37;\n                return connectAudioParam(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY, trace);\n\n              case 37:\n                _context4.next = 39;\n                return connectAudioParam(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ, trace);\n\n              case 39:\n                if (!isNativeAudioNodeFaker(nativePannerNode)) {\n                  _context4.next = 44;\n                  break;\n                }\n\n                _context4.next = 42;\n                return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode.inputs[0], trace);\n\n              case 42:\n                _context4.next = 46;\n                break;\n\n              case 44:\n                _context4.next = 46;\n                return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode, trace);\n\n              case 46:\n                return _context4.abrupt(\"return\", nativePannerNode);\n\n              case 47:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4);\n      }));\n\n      return function createAudioNode(_x, _x2, _x3) {\n        return _ref.apply(this, arguments);\n      };\n    }();\n\n    return {\n      render: function render(proxy, nativeOfflineAudioContext, trace) {\n        var renderedNativeGainNodeOrNativePannerNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n\n        if (renderedNativeGainNodeOrNativePannerNode !== undefined) {\n          return Promise.resolve(renderedNativeGainNodeOrNativePannerNode);\n        }\n\n        return createAudioNode(proxy, nativeOfflineAudioContext, trace);\n      }\n    };\n  };\n};","map":null,"metadata":{},"sourceType":"module"}